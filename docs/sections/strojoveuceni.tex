\section{Strojové učení}
Strojové učení je nedílnou součástí celé kapitoly neuronových sítí. Strojové učení se umožňuje sítím se učit ze známých dat.
Díky strojovému učení je možné řešit problémy, které byly do objevení těchto učících technik neřešitelné.
Existuje několik způsobů učení, ale v této práci bylo použito takzvané učení s učitelem.
To znamená, že všechny data, ze kterých se síť učí jsou předkládána síti se správným výsledkem.
Existují však metody bez učitele, které se dokáží učit i z nepopsaných dat.

Princip storjového učení je,že síť dostane data se správnými výsledky a síť si na základě těchto dat poupraví svoje hodnoty vah a biasů tak,
aby při načtení těchto dat odpověděla příště správně.

\subsection{Zpětné počítání chyby}
Zpětné počítání chyby\cite{backpropagation}, neboli backpropagation, je algoritmus pro hluboké učení neuronových sítí.
Tento algoritmus funguje tak, že se šíří chyba výstupu zpátky do neuronové sítě a podle chyby upravuje postupně váhy a biasy.

Tento algoritmus se skládá ze 4 kroků. Nejprve se musí vyhodnotit chyba. To znamená, že se konkrétní dat nechají vyhodnotit sítí a spočítá se chyba.
Chyba je v tomto případě rozdíl od očekávaného výsledku. Dále se chyba šíří zpět do sítě a počítá se derivace chyby vzhledem ke konkrétním vahám a biasům.
Na základě této derivace se váhy a biasy aktualizují. Tato aktualizace pomáhá zmírňovat celkovou chybu výsledku. Nakonec se tento proces pro všechny trénovací data opakuje.

\subsection{Počítání chyby a aktualizace vah a biasů}
Celková chyba sítě se označuje velkým písmenem \(C\). Při zpětné úpravě vah a biasů nás zajímá jaká je derivace chyby vůči každé váze \(\frac{\delta C}{\delta w}\) a biasu \(\frac{\delta C}{\delta b}\).
V moment, kdy budeme znát tento vztah, tak víme jakým směrem upravit váhu nebo bias, abychom snížili celkovou chybu sítě.

Důležitá část pro pochopení vzorce algoritmu zpětné počítání chyby je notace zápisu neuronové sítě.
Proto je potřeba nejprve definovat zápis a až dále se budu věnovat samotným vzorcům a vztahům při počítání zpětné počítání chyby.
Pro po popsání váhy budem zapisovat jako \(w_{jk}^l\), kde \(l\) je číslo vrstvy, \(j\) je označení,
do kterého neuronu v \(l\)-té vrstvě váha směřuje a číslo \(k\) označuje z kolikátého neuronu z vrstvy \((l-1)\) váha vychází.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{images/vaha_v_siti.png}
    \caption{Příklad zápisu váhy}\cite{vaha_v_siti}
\end{figure}

Podobná notace se použije také při popisu biasu, neaktivované a neaktivované hodnoty neuronu.
Bias neuronu se zapíše jako \(b_{j}^l\), kde \(l\) je vrstva neuronu a \(j\) je \(j\)-tý neuron v \(l\)-té vrstvě.
Hodnota neuronu před aktivací je označí písmenem \(z_{j}^{l} = \left( \sum (w^{l}_{jk} a^{l-1}_k) + b^l_j \right)\).
Hodnota aktivovaného neuronu ze zapíše jako \(a_j^l = \sigma(z_j^l)\).

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{images/bias_a_neuron.png}
    \caption{Příklad zápisu biasu, aktivace a neaktivace neuronu} \cite{bias_a_neuron}
\end{figure}

